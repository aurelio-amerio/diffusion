{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd '/lhome/ific/a/aamerio/github/diffusion'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/lhome/ific/a/aamerio/github/diffusion/src')\n",
    "# sys.path.append('/home/zaldivar/Documents/Aurelio/Github/diffusion/src')\n",
    "sys.path.append('./src')\n",
    "sys.path.append('./reference/simformer-main/src/probjax')\n",
    "sys.path.append('./reference/simformer-main/src/scoresbibm')\n",
    "\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../reference/simformer-main/src/probjax')\n",
    "sys.path.append('../reference/simformer-main/src/scoresbibm')\n",
    "\n",
    "import os\n",
    "# os.environ['JAX_PLATFORMS']=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffusion\n",
    "from diffusion.sbi.transformer import Transformer\n",
    "from diffusion.embedding import GaussianFourierEmbedding, SinusoidalEmbedding\n",
    "from diffusion import sde as sde_ours\n",
    "\n",
    "from scoresbibm.methods.sde import init_sde_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax.default_backend())\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have two parameters, theta1 and theta2\n",
    "# we have two outputs, y1 and y2, corresponding to the measurement with two different detectors\n",
    "\n",
    "npoints = 2**10 #1024\n",
    "\n",
    "nobs = 128_000\n",
    "wavefun = lambda theta1, theta2, x: jnp.sin(theta1*x)*jnp.cos(theta2*x)\n",
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, key = jax.random.split(rng)\n",
    "x1 = np.linspace(0, 4*np.pi, npoints).reshape(1,-1)\n",
    "x2 = np.linspace(0, 4*np.pi, npoints).reshape(1,-1)\n",
    "thetas = jax.random.normal(key, (nobs,2))+0.5\n",
    "noise1 = jax.random.normal(key, (nobs,npoints))*0.3\n",
    "noise2 = jax.random.normal(key, (nobs,npoints))*0.3\n",
    "\n",
    "xs1 = wavefun(thetas[:,0:1], thetas[:,1:2],x1) + noise1\n",
    "xs2 = wavefun(thetas[:,0:1], thetas[:,1:2],x2) + noise2\n",
    "\n",
    "xs1 = xs1.reshape(nobs,1,npoints)\n",
    "xs2 = xs2.reshape(nobs,1,npoints)\n",
    "\n",
    "xs = jnp.concatenate([xs1,xs2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape, thetas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "plt.plot(x1[0,:], xs1[i,0,:], label='y1')\n",
    "plt.plot(x2[0,:], xs2[i,0,:], label='y2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_mean = jnp.mean(thetas, axis=0, keepdims=True)\n",
    "thetas_std = jnp.std(thetas, axis=0, keepdims=True)\n",
    "\n",
    "thetas = (thetas - thetas_mean) / thetas_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_thetas(thetas):\n",
    "    thetas = (thetas - thetas_mean) / thetas_std\n",
    "    return thetas\n",
    "\n",
    "def un_z_score_thetas(thetas):\n",
    "    thetas = thetas * thetas_std + thetas_mean\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_mean = jnp.mean(xs, axis=0, keepdims=True)\n",
    "xs_mean = jnp.mean(xs_mean, axis=-1, keepdims=True)\n",
    "xs_std = jnp.std(xs, axis=0, keepdims=True)\n",
    "xs_std = jnp.std(xs_std, axis=-1, keepdims=True)\n",
    "\n",
    "xs = (xs - xs_mean) / xs_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_xs(xs):\n",
    "    xs = (xs - xs_mean) / xs_std\n",
    "    return xs\n",
    "\n",
    "def un_z_score_xs(xs):\n",
    "    xs = xs * xs_std + xs_mean\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravel(data, axis=-1):\n",
    "    flat_data, tree = jax.tree_util.tree_flatten(data)\n",
    "    split_dims = np.cumsum(np.array([flat.shape[axis] for flat in flat_data]))[:-1]\n",
    "    flat_data = jnp.concatenate(flat_data, axis=axis)\n",
    "    def unravel(flat_data):\n",
    "        flat_data = jnp.split(flat_data, split_dims, axis=axis)\n",
    "        flat_data = jax.tree_util.tree_unflatten(tree, flat_data)\n",
    "        return flat_data\n",
    "    def unflatten(flat_data):\n",
    "        flat_data = jnp.split(flat_data, split_dims, axis=axis)\n",
    "        return flat_data \n",
    "    return flat_data, unravel, unflatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"theta0\": thetas[:, 0][:, None], \"theta1\": thetas[:, 1][:, None], \"x0\": xs[:, 0], \"x1\": xs[:, 1]}\n",
    "data_flat, unravel, unflatten = ravel(data)\n",
    "theta_dim = 2\n",
    "x_dim = data_flat.shape[-1] - theta_dim\n",
    "node_id = jnp.arange(0, 4)\n",
    "condition_mask = jnp.array([False]*theta_dim + [True]*x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve = sde.VESDE(2, sigma_min=1e-5, sigma_max=15.)\n",
    "sde, T_min, T_max, weight_fn, output_scale_fn =  init_sde_related(data_flat, \"vesde\", sigma_min=1e-5, sigma_max=15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model output scale function\n",
    "# scale_min=0\n",
    "# def output_scale_fn(t, x):\n",
    "#     scale = jnp.clip(jnp.sqrt(jnp.sum(ve.variance(t[..., None]))), scale_min)\n",
    "#     return 1/scale[..., None] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a CNN to embed the data\n",
    "class ConvEmbed(nnx.Module):\n",
    "    def __init__(self, din, dout, *, rngs):\n",
    "        features = 16\n",
    "        padding = \"SAME\"\n",
    "        self.activation = jax.nn.gelu\n",
    "        dlin = din\n",
    "        conv1 = nnx.Conv(1, features, kernel_size=(9,), strides=2, padding=padding, rngs=rngs) # 512\n",
    "        dlin/=2\n",
    "        bn1 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv2 = nnx.Conv(features, features*2, kernel_size=(6,), strides=2, padding=padding, rngs=rngs) # 256\n",
    "        dlin/=2\n",
    "        features *= 2\n",
    "        bn2 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv3 = nnx.Conv(features, features*2, kernel_size=(3,), strides=2, padding=padding, rngs=rngs) # 128\n",
    "        dlin/=2\n",
    "        features *= 2\n",
    "        bn3 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv4 = nnx.Conv(features, features*2, kernel_size=(3,), strides=2, padding=padding, rngs=rngs) # 64\n",
    "        dlin/=2\n",
    "        features *= 2\n",
    "        bn4 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv5 = nnx.Conv(features, features*2, kernel_size=(3,), strides=2, padding=padding, rngs=rngs) # 32\n",
    "        dlin/=2\n",
    "        features *= 2\n",
    "        bn5 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv6 = nnx.Conv(features, features, kernel_size=(3,), strides=2, padding=padding, rngs=rngs) # 16\n",
    "        dlin/=2\n",
    "        bn6 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv7 = nnx.Conv(features, features*2, kernel_size=(3,), strides=2, padding=padding, rngs=rngs) # 8\n",
    "        dlin/=2\n",
    "        features*=2\n",
    "        bn7 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        conv8 = nnx.Conv(features, features, kernel_size=(3,), strides=2, padding=padding, rngs=rngs) # 4\n",
    "        dlin/=2\n",
    "        bn8 = nnx.BatchNorm(features, rngs=rngs)\n",
    "        dlin*=features\n",
    "\n",
    "        self.conv_layers = [conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8]\n",
    "        self.bn_layers = [bn1, bn2, bn3, bn4, bn5, bn6, bn7, bn8]\n",
    "\n",
    "        self.linear = nnx.Linear(int(dlin), dout, rngs=rngs)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            x = self.conv_layers[i](x)\n",
    "            x = self.activation(x)\n",
    "            #x = self.bn_layers[i](x)\n",
    "        \n",
    "        #flatten x\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x[..., None,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dim = 100\n",
    "id_dim = 40\n",
    "cond_dim = 10\n",
    "rngs = nnx.Rngs(42)\n",
    "\n",
    "\n",
    "class Simformer(nnx.Module):\n",
    "    def __init__(self, din, *, rngs):\n",
    "        fourier_features = 128\n",
    "        self.unflatten = unflatten\n",
    "        embedding_net1 = lambda x: jnp.repeat(x, token_dim, axis=-1)\n",
    "        embedding_net2 = ConvEmbed(din, token_dim, rngs=rngs)\n",
    "        self.embedding_nets = [\n",
    "            embedding_net1,\n",
    "            embedding_net1,\n",
    "            embedding_net2,\n",
    "            embedding_net2,\n",
    "        ]\n",
    "        self.time_embedder = GaussianFourierEmbedding(fourier_features, rngs=rngs)\n",
    "        # self.time_embedder = SinusoidalEmbedding(fourier_features)\n",
    "        self.id_embedder = nnx.Embed(\n",
    "            num_embeddings=4, features=id_dim, rngs=rngs\n",
    "        )  # hk.Embed(4, id_dim)\n",
    "        self.condition_token = nnx.Param(0.01*jnp.ones((1, 1, cond_dim)))\n",
    "        self.output_scale_fn = output_scale_fn\n",
    "\n",
    "        self.total_tokens = token_dim + id_dim + cond_dim\n",
    "\n",
    "        self.transformer = Transformer(\n",
    "            din=self.total_tokens,\n",
    "            dcontext=fourier_features,\n",
    "            num_heads=4,\n",
    "            num_layers=8,\n",
    "            features=20,\n",
    "            widening_factor=3,\n",
    "            dropout_rate=0,\n",
    "            num_hidden_layers=1,\n",
    "            act=jax.nn.gelu,\n",
    "            skip_connection_attn=True,\n",
    "            skip_connection_mlp=True,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "        self.output_fn = [nnx.Linear(self.total_tokens,1,rngs=rngs), nnx.Linear(self.total_tokens,1,rngs=rngs), nnx.Linear(self.total_tokens,npoints,rngs=rngs), nnx.Linear(self.total_tokens,npoints,rngs=rngs)]\n",
    "\n",
    "\n",
    "    def __call__(self, data, t, data_id, condition_mask, edge_mask=None):\n",
    "        data = self.unflatten(data)\n",
    "        \n",
    "        data_embedded = jax.tree.map(lambda x, net: net(x[..., :,None]), data, self.embedding_nets)\n",
    "\n",
    "        data_embedded = jnp.concatenate(data_embedded, axis=-2)\n",
    "        \n",
    "        _, current_nodes, _ = data_embedded.shape\n",
    "        \n",
    "        \n",
    "        id_embedding = self.id_embedder(data_id)\n",
    "        id_embedding = jnp.broadcast_to(\n",
    "            id_embedding, data_embedded.shape[:-1] + (id_dim,)\n",
    "        )\n",
    "        tokens = jnp.concatenate([data_embedded, id_embedding], axis=-1)\n",
    "        # time = self.time_embedder(t[..., None])\n",
    "        time = self.time_embedder(t)\n",
    "        \n",
    "        condition_mask = self.unflatten(condition_mask)\n",
    "        condition_mask = jax.tree.map(lambda x: jnp.any(x, axis=-1, keepdims=True), condition_mask)\n",
    "        condition_mask = jnp.concatenate(condition_mask, axis=-1)\n",
    "        condition_mask = condition_mask.reshape(-1, current_nodes, 1)\n",
    "        condition_token = condition_mask * self.condition_token\n",
    "    \n",
    "        condition_token = jnp.broadcast_to(\n",
    "            condition_token, tokens.shape[:-1] + (cond_dim,)\n",
    "        )\n",
    "\n",
    "        tokens = jnp.concatenate([tokens, condition_token], -1)\n",
    "\n",
    "        h = self.transformer(tokens, context=time, mask=edge_mask)\n",
    "        out = jnp.split(h, current_nodes, axis=-2)\n",
    "        out = jax.tree.map(lambda x, fn: fn(x), out, self.output_fn)\n",
    "        out = jnp.concatenate(out, axis=-1)\n",
    "        out = jnp.squeeze(out, axis=-2)\n",
    "        out = self.output_scale_fn(t, out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = Simformer(x_dim//2, rngs=nnx.Rngs(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model( data_flat[:10], jnp.ones((1,)), node_id, condition_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "optimizer = nnx.Optimizer(score_model, optax.adam(1e-4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def denoising_score_matching_loss(\n",
    "    # params: PyTree,\n",
    "    # key: PRNGKey,\n",
    "    # times: Array,\n",
    "    # xs_target: Array,\n",
    "    # loss_mask: Optional[Array],\n",
    "    # *args,\n",
    "    # model_fn: Callable,\n",
    "    # mean_fn: Callable,\n",
    "    # std_fn: Callable,\n",
    "    # weight_fn: Callable,\n",
    "    # axis: int = -2,\n",
    "    # rebalance_loss: bool = False,\n",
    "    score_model,\n",
    "    key,\n",
    "    times,\n",
    "    xs_target,\n",
    "    loss_mask,\n",
    "    *args,\n",
    "    mean_fn,\n",
    "    std_fn,\n",
    "    weight_fn,\n",
    "    axis: int = -2,\n",
    "    rebalance_loss: bool = False,\n",
    "    **kwargs): \n",
    "    \"\"\"This function computes the denoising score matching loss. Which can be used to train diffusion models.\n",
    "\n",
    "    Args:\n",
    "        params (PyTree): Parameters of the model_fn given as a PyTree.\n",
    "        key (PRNGKey): Random generator key.\n",
    "        times (Array): Time points, should be broadcastable to shape (batch_size, 1).\n",
    "        xs_target (Array): Target distribution.\n",
    "        loss_mask (Optional[Array]): Mask for the target distribution. If None, no mask is applied, should be broadcastable to shape (batch_size, 1).\n",
    "        model_fn (Callable): Score model that takes parameters, times, and samples as input and returns the score. Should be a function of the form model_fn(params, times, xs_t, *args) -> s_t.\n",
    "        mean_fn (Callable): Mean function of the SDE.\n",
    "        std_fn (Callable): Std function of the SDE.\n",
    "        weight_fn (Callable): Weight function for the loss.\n",
    "        axis (int, optional): Axis to sum over. Defaults to -2.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        Array: Loss\n",
    "    \"\"\"\n",
    "    eps = jax.random.normal(key, shape=xs_target.shape)\n",
    "    mean_t = mean_fn(times, xs_target)\n",
    "    std_t = std_fn(times, xs_target)\n",
    "    xs_t = mean_t + std_t * eps\n",
    "    \n",
    "    if loss_mask is not None:\n",
    "        loss_mask = loss_mask.reshape(xs_target.shape)\n",
    "        xs_t = jnp.where(loss_mask, xs_target, xs_t)\n",
    "    \n",
    "    score_pred = score_model(xs_t, times , *args, **kwargs)\n",
    "    score_target = -eps / std_t\n",
    "\n",
    "    loss = (score_pred - score_target) ** 2\n",
    "    if loss_mask is not None:\n",
    "        loss = jnp.where(loss_mask, 0.0,loss)\n",
    "    loss = weight_fn(times) * jnp.sum(loss, axis=axis, keepdims=True)\n",
    "    if rebalance_loss:\n",
    "        num_elements = jnp.sum(~loss_mask, axis=axis, keepdims=True)\n",
    "        loss = jnp.where(num_elements > 0, loss / num_elements, 0.0)\n",
    "    loss = jnp.mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_(score_model, key, data, node_id):\n",
    "    key_times, key_loss, key_condition = jax.random.split(key,3)\n",
    "    times = jax.random.uniform(key_times, (data.shape[0],), minval=T_min, maxval =T_max)\n",
    "    condition_mask1 = jnp.array([False]*theta_dim + [True]*x_dim)\n",
    "    condition_mask2 = jnp.array([False]*theta_dim + [True]*(x_dim//2) + [False]*(x_dim//2))\n",
    "    condition_mask3 = jnp.array([False]*theta_dim + [False]*(x_dim//2) + [True]*(x_dim//2))\n",
    "\n",
    "    edge_mask1 = jnp.ones((4,4), dtype=bool)\n",
    "    # Partial posterior\n",
    "    edge_mask2 = edge_mask1.at[:, 2].set(False)\n",
    "    edge_mask2 = edge_mask2.at[2, :].set(False)\n",
    "    # Partial posterior 2\n",
    "    edge_mask3 = edge_mask1.at[:, 3].set(False)\n",
    "    edge_mask3 = edge_mask3.at[3, :].set(False)\n",
    "    \n",
    "    edge_masks = jax.random.choice(key_condition, jnp.stack([edge_mask1, edge_mask2, edge_mask3]), (data.shape[0],))\n",
    "    condition_mask = jax.random.choice(key_condition, jnp.stack([condition_mask1, condition_mask2, condition_mask3]), (data.shape[0],))\n",
    "    l_mask = jnp.broadcast_to(condition_mask1, (data.shape[0],) + condition_mask1.shape)\n",
    "    \n",
    "    loss = denoising_score_matching_loss(score_model, key_loss, times, data, l_mask, node_id,  mean_fn = sde.marginal_mean, std_fn=sde.marginal_stddev, weight_fn=weight_fn, edge_mask=edge_masks, condition_mask=condition_mask, axis=-1)\n",
    "    return loss\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(score_model, optimizer, data, node_id, rngs):\n",
    "    loss_fn = lambda score_model: loss_fn_(score_model, rngs.dist(), data, node_id)\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(score_model)\n",
    "    optimizer.update(grads)  # In place updates.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 5\n",
    "batch_size = 128\n",
    "batch_steps = nobs // batch_size \n",
    "subkey = rngs.batch()\n",
    "data_batches = jax.random.choice(subkey, data_flat, (batch_steps, batch_size), replace=False)\n",
    "\n",
    "train_step(score_model, optimizer, data_batches[0], node_id, rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 10\n",
    "batch_size = 128\n",
    "batch_steps = nobs // batch_size \n",
    "\n",
    "score_model.train()\n",
    "\n",
    "for _ in range(nepochs):\n",
    "    pbar = tqdm(range(batch_steps))\n",
    "    subkey = rngs.batch()\n",
    "    data_batches = jax.random.choice(subkey, data_flat, (batch_steps, batch_size), replace=False)\n",
    "    l = 0\n",
    "    for j in pbar:\n",
    "        loss = train_step(score_model, optimizer, data_batches[j], node_id, rngs)\n",
    "        l += loss.item()\n",
    "        if j % 10 == 0:\n",
    "            pbar.set_postfix(loss=l/(j+1))\n",
    "    # print(l)\n",
    "\n",
    "score_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save and restore model\n",
    "see https://colab.research.google.com/drive/1ozln9ejG7eRtxvbkqHYU3K6OyPvveH9w?usp=sharing#scrollTo=HleXYZe3Fn38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save the model using orbax\n",
    "from orbax import checkpoint as ocp\n",
    "ckpt_dir = \"/lhome/ific/a/aamerio/data/diffusion/checkpoints/state_score_model\"\n",
    "ckpt_dir = str(ocp.test_utils.erase_and_create_empty(ckpt_dir))\n",
    "\n",
    "\n",
    "graphdef, state = nnx.split(score_model)\n",
    "\n",
    "# Flatten the model state\n",
    "model_state = state.flat_state()\n",
    "\n",
    "# Generating a 'true' model state for later comparison to restored state\n",
    "model_state_true = state.flat_state()\n",
    "\n",
    "# checkpointer = ocp.StandardCheckpointer()\n",
    "\n",
    "# checkpointer.save(ckpt_dir + \"/state_score_model\", state)\n",
    "def prepare_state_for_saving(model_state):\n",
    "    \"\"\"\n",
    "    Converts RNG keys in the model state to arrays of uint32 numbers for saving.\n",
    "\n",
    "    Args:\n",
    "        model_state (Dict): The flattened model state.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The updated model state with RNG keys converted.\n",
    "    \"\"\"\n",
    "    new_model_state = model_state.copy()\n",
    "    for key_path, var_state in new_model_state.items():\n",
    "        if var_state.type == nnx.RngKey:\n",
    "            # Convert the RNG key into an array of uint32 numbers\n",
    "            uint32_array = jax.random.key_data(var_state.value)\n",
    "            # Replace the RNG key in the model state with the array\n",
    "            new_model_state[key_path] = nnx.VariableState(\n",
    "                type=nnx.Param,\n",
    "                value=uint32_array\n",
    "            )\n",
    "    return new_model_state\n",
    "model_state_to_save = prepare_state_for_saving(model_state)\n",
    "# Define CheckpointManagerOptions\n",
    "options = ocp.CheckpointManagerOptions(\n",
    "    max_to_keep=2,\n",
    "    keep_checkpoints_without_metrics=False,\n",
    "    create=True,\n",
    ")\n",
    "\n",
    "# Initialize the CheckpointManager\n",
    "checkpoint_manager = ocp.CheckpointManager(\n",
    "    directory=ckpt_dir,\n",
    "    options=options,\n",
    ")\n",
    "# Save the checkpoint using StandardSave\n",
    "checkpoint_manager.save(\n",
    "    step=0,\n",
    "    args=ocp.args.StandardSave(nnx.State.from_flat_path(model_state_to_save)),\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "# Ensure checkpointing is finished\n",
    "checkpoint_manager.wait_until_finished()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_dir = \"/lhome/ific/a/aamerio/data/diffusion/checkpoints/state_score_model\"\n",
    "\n",
    "# Define CheckpointManagerOptions\n",
    "options = ocp.CheckpointManagerOptions(\n",
    "    max_to_keep=2,\n",
    "    keep_checkpoints_without_metrics=False,\n",
    "    create=True,\n",
    ")\n",
    "\n",
    "# Initialize the CheckpointManager\n",
    "checkpoint_manager = ocp.CheckpointManager(\n",
    "    directory=ckpt_dir,\n",
    "    options=options,\n",
    ")\n",
    "# New model, with same structure\n",
    "new_model = Simformer(x_dim//2, rngs=nnx.Rngs(42))\n",
    "# Create a placeholder for the model state shape\n",
    "model_shape = nnx.eval_shape(lambda: nnx.State.from_flat_path(model_state_to_save))\n",
    "\n",
    "# Restore the model state from the checkpoint\n",
    "restored_model_state = checkpoint_manager.restore(\n",
    "    0,\n",
    "    args=ocp.args.StandardRestore(model_shape),\n",
    ")\n",
    "def restore_rng_keys(model_state):\n",
    "    \"\"\"\n",
    "    Converts arrays of uint32 numbers back to RNG keys in the model state.\n",
    "\n",
    "    Args:\n",
    "        model_state (Dict): The flattened model state.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The updated model state with RNG keys restored.\n",
    "    \"\"\"\n",
    "    new_model_state = model_state.copy()\n",
    "    for key_path, var_state in new_model_state.items():\n",
    "        if var_state.type == nnx.Param and ('rngs' in key_path) and (key_path[-1] == 'key'):\n",
    "            # Convert the array back to an RNG key\n",
    "            rng_key = jax.random.wrap_key_data(var_state.value)\n",
    "            # Replace the array with the RNG key\n",
    "            new_model_state[key_path] = nnx.VariableState(\n",
    "                type=nnx.RngKey,\n",
    "                value=jax.random.wrap_key_data(var_state.value),\n",
    "                get_value_hooks=(),\n",
    "                set_value_hooks=(),\n",
    "                create_value_hooks=(),\n",
    "                add_axis_hooks=(),\n",
    "                remove_axis_hooks=(),\n",
    "                tag='default',\n",
    "            )\n",
    "    return new_model_state\n",
    "# Flatten the restored model state\n",
    "restored_state_flat = restored_model_state.flat_state()\n",
    "\n",
    "# Convert arrays back to RNG keys\n",
    "restored_state_flat = restore_rng_keys(restored_state_flat)\n",
    "# update the model with a checkpoint\n",
    "# Create nnx.State from the restored flat state\n",
    "restored_state = nnx.State.from_flat_path(restored_state_flat)\n",
    "\n",
    "# Update the model with the restored state\n",
    "nnx.update(new_model, restored_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we do the backward diffusion to get the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve = sde_ours.VESDE(2050, sigma_min=1e-5, sigma_max=15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 100\n",
    "\n",
    "rng = jax.random.PRNGKey(420)\n",
    "rng, key = jax.random.split(rng)\n",
    "x1 = np.linspace(0, 4*np.pi, npoints).reshape(1,-1)\n",
    "x2 = np.linspace(0, 4*np.pi, npoints).reshape(1,-1)\n",
    "thetas_test = jax.random.normal(key, (nobs,2))+0.2\n",
    "noise1 = jax.random.normal(key, (nobs,npoints))*0.3\n",
    "noise2 = jax.random.normal(key, (nobs,npoints))*0.3\n",
    "\n",
    "xs1 = wavefun(thetas_test[:,0:1], thetas_test[:,1:2],x1) + noise1\n",
    "xs2 = wavefun(thetas_test[:,0:1], thetas_test[:,1:2],x2) + noise2\n",
    "\n",
    "xs1 = xs1.reshape(nobs,1,npoints)\n",
    "xs2 = xs2.reshape(nobs,1,npoints)\n",
    "\n",
    "xs_test = jnp.concatenate([xs1,xs2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_test = (thetas_test - thetas_mean) / thetas_std\n",
    "xs_test = (xs_test - xs_mean) / xs_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = {\"theta0\": thetas_test[:, 0][:, None], \"theta1\": thetas_test[:, 1][:, None], \"x0\": xs_test[:, 0], \"x1\": xs_test[:, 1]}\n",
    "data_test_flat, _, _ = ravel(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_mask = jnp.ones((4,4), dtype=bool)\n",
    "edge_mask1 = edge_mask.at[:, 2].set(False)\n",
    "edge_mask1 = edge_mask1.at[2, :].set(False)\n",
    "\n",
    "edge_mask2 = edge_mask.at[:, 3].set(False)\n",
    "edge_mask2 = edge_mask2.at[3, :].set(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42\n",
    "x_o = jax.device_put(data_test_flat[index], jax.devices(\"gpu\")[0])\n",
    "x_o[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = ve.reverse(score_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "score_args = {\"data_id\": node_id, \"condition_mask\": condition_mask, \"edge_mask\": edge_mask}\n",
    "sample = rev.sample(rng, 1000, condition_mask=condition_mask, condition_value=x_o, score_args=score_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "score_args = {\"data_id\": node_id, \"condition_mask\": condition_mask, \"edge_mask\": edge_mask1}\n",
    "sample_partial1 = rev.sample(rng, 1000, condition_mask=condition_mask, condition_value=x_o, score_args=score_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "score_args = {\"data_id\": node_id, \"condition_mask\": condition_mask, \"edge_mask\": edge_mask2}\n",
    "sample_partial2 = rev.sample(rng, 1000, condition_mask=condition_mask, condition_value=x_o, score_args=score_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = jax.device_put(sample, jax.devices(\"gpu\")[0])\n",
    "# sample_partial1 = jax.device_put(sample_partial1, jax.devices(\"gpu\")[0])\n",
    "# sample_partial2 = jax.device_put(sample_partial2, jax.devices(\"gpu\")[0])\n",
    "# x_o = jax.device_put(data_test_flat[index], jax.devices(\"gpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_sampled = un_z_score_thetas(sample[:, :2])\n",
    "thetas_partial1 = un_z_score_thetas(sample_partial1[:, :2])\n",
    "thetas_partial2 = un_z_score_thetas(sample_partial2[:, :2])\n",
    "theta_true = un_z_score_thetas(x_o[:2].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"theta1\":thetas_sampled[:, 0], \"theta2\":thetas_sampled[:, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df,x=\"theta1\", y=\"theta2\", kind=\"kde\", xlim=[-10,10], ylim=[-10,10])\n",
    "plt.scatter(theta_true[:,0], theta_true[:,1], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df,x=\"theta1\", y=\"theta2\", kind=\"hex\", xlim=[-10,10], ylim=[-10,10])\n",
    "plt.scatter(theta_true[:,0], theta_true[:,1], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = {\"theta1\":thetas_sampled[:, 0], \"theta2\":thetas_sampled[:, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(data_, bins=21, range=[[-10,10],[-15,15]],\n",
    "                       quantiles=[0.16, 0.5, 0.84],show_titles=True,\n",
    "                       truths=theta_true[0],\n",
    "                      plot_contours=True,\n",
    "                      smooth=None)\n",
    "#axes = np.array(figure.axes).reshape((2, 2))\n",
    "#axes[1,0].scatter(theta_true[:,0], theta_true[:,1], color=\"red\", zorder=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# bins1 = np.linspace(-np.pi, np.pi, 101)\n",
    "# bins2 = np.linspace(0, np.pi, 101)\n",
    "\n",
    "#xlim = [-1,1]\n",
    "#ylim=[1.2,2.0]\n",
    "xlim = [-4*np.pi,4*np.pi]\n",
    "ylim=[-4*np.pi,4*np.pi]\n",
    "\n",
    "bins1 = np.linspace(*xlim, 51)\n",
    "bins2 = np.linspace(*ylim, 51)\n",
    "\n",
    "\n",
    "plt.plot(theta_true[0,0], lw=0.1, color=\"black\")\n",
    "plt.title(\"detector 1\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(theta_true[0,1],lw=0.1, color=\"black\")\n",
    "plt.title(\"detector 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(thetas_sampled[:, 0], thetas_sampled[:, 1], bins=[bins1,bins2], density=False)\n",
    "plt.scatter(theta_true[:,0], theta_true[:,1], color=\"red\")\n",
    "plt.colorbar()\n",
    "# ax1.scatter(theta_true[:,0], theta_true[:,1], color=\"red\")\n",
    "plt.title(\"Full posterior (detect. 1+2)\", y=1.1)\n",
    "plt.xlabel(\"Mass 1\")\n",
    "plt.ylabel(\"Mass 2\")\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(thetas_partial1[:, 0], thetas_partial1[:, 1], bins=[bins1,bins2], density=False)\n",
    "plt.scatter(theta_true[:,0], theta_true[:,1], color=\"red\")\n",
    "plt.xlabel(\"Mass 1\")\n",
    "plt.ylabel(\"Mass 2\")\n",
    "plt.title(\"Partial posterior (detect. 1)\", y=1.1)\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist2d(thetas_partial2[:, 0], thetas_partial2[:, 1], bins=[bins1,bins2], density=False)\n",
    "plt.scatter(theta_true[:,0], theta_true[:,1], color=\"red\")\n",
    "plt.xlabel(\"Mass 1\")\n",
    "plt.ylabel(\"Mass 2\")\n",
    "plt.title(\"Partial posterior (detect. 2)\", y=1.1)\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

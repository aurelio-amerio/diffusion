{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAX_PLATFORMS']=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#   from utils import install_packages\n",
    "# except:\n",
    "#   # Colab\n",
    "#   !git clone https://github.com/mackelab/simformer.git\n",
    "#   from simformer.example.utils import install_packages\n",
    "#   from google.colab import output\n",
    "#   output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can run for 4 min if nothing is installed/has to be down/upgraded\n",
    "# install_packages() # install required packages if necessary, might requires restarting the kernel/colab runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lhome/ific/a/aamerio/github/diffusion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/lhome/ific/a/aamerio/github/diffusion'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd '/lhome/ific/a/aamerio/github/diffusion'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')\n",
    "sys.path.append('./reference/simformer-main/src/probjax')\n",
    "sys.path.append('./reference/simformer-main/src/scoresbibm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-12GB\n",
      "Tesla P100-PCIE-12GB\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "from jax.random import PRNGKey\n",
    "from jax import Array\n",
    "from flax import nnx\n",
    "import os\n",
    "jax.devices() # Should be cuda\n",
    "_ = os.system(\"nvidia-smi  --query-gpu=name --format=csv,noheader\") # Should show GPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "import haiku as hk # Neural network library\n",
    "import optax # Gradient-based optimization in JAX\n",
    "\n",
    "# Some small helper functions\n",
    "# from probjax.nn.transformers import Transformer\n",
    "# from probjax.nn.helpers import GaussianFourierEmbedding\n",
    "from probjax.nn.loss_fn import denoising_score_matching_loss\n",
    "from probjax.distributions.sde import VESDE\n",
    "from probjax.distributions import Empirical, Independent\n",
    "import diffusion\n",
    "from diffusion.sbi.transformer import Transformer\n",
    "from diffusion.embedding import GaussianFourierEmbedding, SinusoidalEmbedding\n",
    "from diffusion import sde as sde_ours\n",
    "from scoresbibm.methods.sde import init_sde_related\n",
    "\n",
    "# from scoresbibm.utils.plot import use_style\n",
    "\n",
    "from sbi.analysis import pairplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random key\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1) Setting up a toy problem\n",
    "\n",
    "This is a simple toy problem to test the functionality of the `Simformer` method.\n",
    "$$ \\theta \\sim \\mathcal{N}(\\theta; 0, 3^2) \\qquad \\qquad  x_1 \\sim \\mathcal{N}(x_1; 2\\cdot\\sin(\\theta), 0.5^2)  \\qquad \\qquad   x_2 \\sim \\mathcal{N}(x_2;0.1\\cdot \\theta^2,  (0.5\\cdot |x_1|)^2)$$\n",
    "\n",
    "Here we have 3 nonlinear related Gaussian variables. The associated joint distirbution is visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(key: PRNGKey, n:int):\n",
    "    key1, key2, key3 = jrandom.split(key,3)\n",
    "    theta1 = jrandom.normal(key1, (n, 1))  * 3 # Some prior on a parameter\n",
    "    x1 = 2*jnp.sin(theta1) + jrandom.normal(key2, (n, 1)) * 0.5 # Some data generated from the parameter \n",
    "    x2 = 0.1*theta1**2 + 0.5*jnp.abs(x1)*jrandom.normal(key3, (n, 1)) # Some data generated from the parameter\n",
    "    return jnp.concatenate([theta1,x1, x2], axis=1).reshape(n, -1, 1)\n",
    "\n",
    "def log_potential(theta1: Array, x1: Array, x2: Array, sigma_x1:float=0.5, sigma_x2:float=0.5, mean_loc:float=0.0, mean_scale:float=3.0 ):\n",
    "    log_prob_theta = jax.scipy.stats.norm.logpdf(theta1, mean_loc, mean_scale)\n",
    "    if x1 is not None:\n",
    "        log_prob_x1 = jax.scipy.stats.norm.logpdf(x1, 2*jnp.sin(theta1), sigma_x1)\n",
    "    else:\n",
    "        log_prob_x1 = 0\n",
    "    if x2 is not None:\n",
    "        log_prob_x2 = jax.scipy.stats.norm.logpdf(x2, 0.1*theta1**2,  sigma_x2*jnp.abs(x1))\n",
    "    else:\n",
    "        log_prob_x2 = 0\n",
    "    \n",
    "    return log_prob_theta + log_prob_x1 + log_prob_x2\n",
    "    \n",
    "\n",
    "data = generate_data(jrandom.PRNGKey(1), 10000)  # Shape: (n, nodes, dim) here dim = 1\n",
    "nodes_max = data.shape[1]\n",
    "node_ids = jnp.arange(nodes_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = pairplot(np.array(data[...,0]), labels=[\"theta\", \"x1\", \"x2\"], figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2) Setting up the diffusion process\n",
    "\n",
    "We will use the VESDE i.e. the variance exploding stochastic differential equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# VESDE \n",
    "T = 1.\n",
    "T_min = 1e-2\n",
    "sigma_min = 1e-3\n",
    "sigma_max = 15.\n",
    "\n",
    "p0 = Independent(Empirical(data), 1) # Empirical distribution of the data\n",
    "sde = VESDE(p0, sigma_min=sigma_min , sigma_max=sigma_max)\n",
    "\n",
    "# Scaling fn for the output of the score model\n",
    "def output_scale_fn(t, x):\n",
    "    scale = jnp.clip(sde.marginal_stddev(t, jnp.ones_like(x)), 1e-2, None)\n",
    "    return (1/scale * x).reshape(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3) Building the Simformer\n",
    "\n",
    "This can be divided into two parts, each offering various choices:\n",
    "\n",
    "* **Tokenizer**: \n",
    "This component jointly embeds 'x', 'node_ids', and the 'condition_mask' into a unified \n",
    "vector known as a token.\n",
    "    * **Value Embedding**: Embeds the value of the variable.\n",
    "    * **Node Embedding**: Embeds the node ID.\n",
    "    * **Condition Embedding**: Embeds the condition mask.\n",
    "* **Transformer**: This is a transformer model that takes tokens as input and generates scores for each node.\n",
    "    * **Num_heads**: Specifies the number of heads in the multi-head attention mechanism.\n",
    "    * **Attn_size**: Determines the size of attention, i.e., the dimensions to which query and key are projected.\n",
    "    * **Num_layers**: Sets the number of layers in the transformer.\n",
    "    * **Widening_factor**: Specifies the factor by which the hidden size of the MLP is increased in each layer.\n",
    "\n",
    "In this example, we construct a compact Simformer with 2 layers and 2 heads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_value = 20      # Size of the value embedding, which is token_dim\n",
    "dim_id = 20         # Size of the node id embedding\n",
    "dim_condition = 10  # Size of the condition embedding\n",
    "\n",
    "class Simformer(nnx.Module):\n",
    "    def __init__(self, *, rngs):\n",
    "\n",
    "        self.embedding_net_value = lambda x: jnp.repeat(x, dim_value, axis=-1)\n",
    "\n",
    "        fourier_features=64\n",
    "        self.embedding_time = GaussianFourierEmbedding(fourier_features, rngs=rngs)\n",
    "        self.embedding_net_id = nnx.Embed(\n",
    "            num_embeddings=nodes_max, features=dim_id, rngs=rngs\n",
    "        ) \n",
    "        self.condition_embedding = nnx.Param(0.01*jnp.ones((1, 1, dim_condition)))\n",
    "\n",
    "        self.output_scale_fn = output_scale_fn\n",
    "\n",
    "        self.total_tokens = dim_value + dim_id + dim_condition\n",
    "\n",
    "        self.transformer = Transformer(\n",
    "            din=self.total_tokens,\n",
    "            dcontext=fourier_features,\n",
    "            num_heads=2,\n",
    "            num_layers=2,\n",
    "            features=10,\n",
    "            widening_factor=3,\n",
    "            dropout_rate=0,\n",
    "            num_hidden_layers=1,\n",
    "            act=jax.nn.gelu,\n",
    "            skip_connection_attn=True,\n",
    "            skip_connection_mlp=True,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "        self.output_fn = nnx.Linear(self.total_tokens,1,rngs=rngs)\n",
    "        return\n",
    "    \n",
    "    def __call__(self, x, t, node_ids, condition_mask, edge_mask=None):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        condition_mask = condition_mask.astype(jnp.bool_).reshape(-1,seq_len, 1)\n",
    "        node_ids = node_ids.reshape(-1,seq_len)\n",
    "        t = t.reshape(-1,1, 1)\n",
    "\n",
    "        time_embeddings = self.embedding_time(t)\n",
    "\n",
    "        condition_embedding = self.condition_embedding * condition_mask # If condition_mask is 0, then the embedding is 0, otherwise it is the condition_embedding vector\n",
    "        condition_embedding = jnp.broadcast_to(condition_embedding, (batch_size, seq_len, dim_condition))\n",
    "\n",
    "        # Embed inputs and broadcast\n",
    "        value_embeddings = self.embedding_net_value(x)\n",
    "        id_embeddings = self.embedding_net_id(node_ids)\n",
    "        value_embeddings, id_embeddings = jnp.broadcast_arrays(value_embeddings, id_embeddings)\n",
    "\n",
    "        # Concatenate embeddings (alternatively you can also add instead of concatenating)\n",
    "        x_encoded = jnp.concatenate([value_embeddings, id_embeddings, condition_embedding], axis=-1)\n",
    "\n",
    "        h = self.transformer(x_encoded, context=time_embeddings, mask=edge_mask)\n",
    "\n",
    "        out = self.output_fn(h)\n",
    "        out = self.output_scale_fn(t, out)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# dim_value = 20      # Size of the value embedding\n",
    "# dim_id = 20         # Size of the node id embedding\n",
    "# dim_condition = 10  # Size of the condition embedding\n",
    "\n",
    "\n",
    "# def model(t: Array, x: Array, node_ids: Array, condition_mask:Array, edge_mask: Optional[Array]=None):\n",
    "#     \"\"\"Simplified Simformer model.\n",
    "\n",
    "#     Args:\n",
    "#         t (Array): Diffusion time\n",
    "#         x (Array): Value of the nodes\n",
    "#         node_ids (Array): Id of the nodes\n",
    "#         condition_mask (Array): Condition state of the nodes\n",
    "#         edge_mask (Array, optional): Edge mask. Defaults to None.\n",
    "\n",
    "#     Returns:\n",
    "#         Array: Score estimate of p(x_t)\n",
    "#     \"\"\"\n",
    "#     batch_size, seq_len, _ = x.shape\n",
    "#     condition_mask = condition_mask.astype(jnp.bool_).reshape(-1,seq_len, 1)\n",
    "#     node_ids = node_ids.reshape(-1,seq_len)\n",
    "#     t = t.reshape(-1,1, 1)\n",
    "    \n",
    "#     # Diffusion time embedding net (here we use a Gaussian Fourier embedding)\n",
    "#     embedding_time = GaussianFourierEmbedding(64)  # Time embedding method\n",
    "#     time_embeddings = embedding_time(t)\n",
    "    \n",
    "#     # Tokinization part --------------------------------------------------------------------------------\n",
    "\n",
    "#     embedding_net_value = lambda x: jnp.repeat(x, dim_value, axis=-1)    # Value embedding net (here we just repeat the value)\n",
    "#     embedding_net_id = hk.Embed(nodes_max, dim_id, w_init=hk.initializers.RandomNormal(stddev=3.))   # Node id embedding nets (here we use a learnable random embedding vector)\n",
    "#     condition_embedding = hk.get_parameter(\"condition_embedding\", shape=(1,1,dim_condition), init=hk.initializers.RandomNormal(stddev=0.5)) # Condition embedding (here we use a learnable random embedding vector)\n",
    "#     condition_embedding = condition_embedding * condition_mask # If condition_mask is 0, then the embedding is 0, otherwise it is the condition_embedding vector\n",
    "#     condition_embedding = jnp.broadcast_to(condition_embedding, (batch_size, seq_len, dim_condition))\n",
    "    \n",
    "#     # Embed inputs and broadcast\n",
    "#     value_embeddings = embedding_net_value(x)\n",
    "#     id_embeddings = embedding_net_id(node_ids)\n",
    "#     value_embeddings, id_embeddings = jnp.broadcast_arrays(value_embeddings, id_embeddings)\n",
    "    \n",
    "#     # Concatenate embeddings (alternatively you can also add instead of concatenating)\n",
    "#     x_encoded = jnp.concatenate([value_embeddings, id_embeddings, condition_embedding], axis=-1)\n",
    "    \n",
    "#     # Transformer part --------------------------------------------------------------------------------\n",
    "#     model = Transformer(num_heads=2, num_layers=2, attn_size=10, widening_factor=3) \n",
    "    \n",
    "#     # Encode - here we just use a transformer to transform the tokenized inputs into a latent representation\n",
    "#     h = model(x_encoded, context=time_embeddings, mask=edge_mask)\n",
    "\n",
    "#     # Decode - here we just use a linear layer to get the score estimate (we scale the output by the marginal std dev)\n",
    "#     out = hk.Linear(1)(h)\n",
    "#     out = output_scale_fn(t, out) # SDE dependent output scaling\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # In Haiku, we need to initialize the model first, before we can use it.\n",
    "# init, model_fn = hk.without_apply_rng(hk.transform(model)) # Init function initializes the parameters of the model, model_fn is the actual model function (which takes the parameters as first argument, hence is a \"pure function\")\n",
    "# params = init(key, jnp.ones(data.shape[0]), data, node_ids, jnp.zeros_like(node_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# # Here we can see the total number of parameters and their shapes\n",
    "# print(\"Total number of parameters: \", jax.tree_util.tree_reduce(lambda x,y: x+y, jax.tree_map(lambda x: x.size, params)))\n",
    "# jax.tree_util.tree_map(lambda x: x.shape, params) # Here we can see the shapes of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = Simformer(rngs=nnx.Rngs(0))\n",
    "score_model(data, jnp.ones((1,)),node_ids, jnp.zeros_like(node_ids)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "optimizer = nnx.Optimizer(score_model, optax.adam(1e-4))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4) The loss\n",
    "Here we will show the variant which targets to learn:\n",
    "\n",
    "* Correct joint $p(\\theta,x_1, x_2)$\n",
    "* Correct conditionals $p(\\theta|x), p(x|\\theta), ...$\n",
    "* Correct marginals $p(\\theta), p(x), ...$\n",
    "    \n",
    "Base loss is an **denoising score matching objective**:\n",
    "$$ \\mathcal{L}(\\phi) = \\mathbb{E}_{t \\sim Unif(0,1)} \\left[ \\lambda(t) \\mathbb{E}_{x_0, x_t \\sim p(x_0)p(x_t|x_0)}\\left[ || s_\\phi(x_t, t) - \\nabla_{x_t} \\log p(x_t|x_0)||_2^2 \\right] \\right] $$\n",
    "all the different *targets* will be implemented through masking out different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def denoising_score_matching_loss(\n",
    "    # params: PyTree,\n",
    "    # key: PRNGKey,\n",
    "    # times: Array,\n",
    "    # xs_target: Array,\n",
    "    # loss_mask: Optional[Array],\n",
    "    # *args,\n",
    "    # model_fn: Callable,\n",
    "    # mean_fn: Callable,\n",
    "    # std_fn: Callable,\n",
    "    # weight_fn: Callable,\n",
    "    # axis: int = -2,\n",
    "    # rebalance_loss: bool = False,\n",
    "    score_model,\n",
    "    key,\n",
    "    times,\n",
    "    xs_target,\n",
    "    loss_mask,\n",
    "    *args,\n",
    "    mean_fn,\n",
    "    std_fn,\n",
    "    weight_fn,\n",
    "    axis: int = -2,\n",
    "    rebalance_loss: bool = False,\n",
    "    **kwargs): \n",
    "    \"\"\"This function computes the denoising score matching loss. Which can be used to train diffusion models.\n",
    "\n",
    "    Args:\n",
    "        params (PyTree): Parameters of the model_fn given as a PyTree.\n",
    "        key (PRNGKey): Random generator key.\n",
    "        times (Array): Time points, should be broadcastable to shape (batch_size, 1).\n",
    "        xs_target (Array): Target distribution.\n",
    "        loss_mask (Optional[Array]): Mask for the target distribution. If None, no mask is applied, should be broadcastable to shape (batch_size, 1).\n",
    "        model_fn (Callable): Score model that takes parameters, times, and samples as input and returns the score. Should be a function of the form model_fn(params, times, xs_t, *args) -> s_t.\n",
    "        mean_fn (Callable): Mean function of the SDE.\n",
    "        std_fn (Callable): Std function of the SDE.\n",
    "        weight_fn (Callable): Weight function for the loss.\n",
    "        axis (int, optional): Axis to sum over. Defaults to -2.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        Array: Loss\n",
    "    \"\"\"\n",
    "    eps = jax.random.normal(key, shape=xs_target.shape)\n",
    "    mean_t = mean_fn(times, xs_target)\n",
    "    std_t = std_fn(times, xs_target)\n",
    "    xs_t = mean_t + std_t * eps\n",
    "    \n",
    "    if loss_mask is not None:\n",
    "        loss_mask = loss_mask.reshape(xs_target.shape)\n",
    "        xs_t = jnp.where(loss_mask, xs_target, xs_t)\n",
    "    \n",
    "    score_pred = score_model(xs_t, times , *args, **kwargs)\n",
    "    score_target = -eps / std_t\n",
    "\n",
    "    loss = (score_pred - score_target) ** 2\n",
    "    if loss_mask is not None:\n",
    "        loss = jnp.where(loss_mask, 0.0,loss)\n",
    "    loss = weight_fn(times) * jnp.sum(loss, axis=axis, keepdims=True)\n",
    "    if rebalance_loss:\n",
    "        num_elements = jnp.sum(~loss_mask, axis=axis, keepdims=True)\n",
    "        loss = jnp.where(num_elements > 0, loss / num_elements, 0.0)\n",
    "    loss = jnp.mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def weight_fn(t:Array):\n",
    "    # MLE weighting\n",
    "    return jnp.clip(sde.diffusion(t, jnp.ones((1,1,1)))**2, 1e-4)\n",
    "\n",
    "def marginalize(rng: PRNGKey, edge_mask: Array):\n",
    "    # Simple function that marginializes out a single node from a adjacency matrix of a graph.\n",
    "    idx = jax.random.choice(rng, jnp.arange(edge_mask.shape[0]), shape=(1,), replace=False)\n",
    "    edge_mask = edge_mask.at[idx, :].set(False)\n",
    "    edge_mask = edge_mask.at[:, idx].set(False)\n",
    "    edge_mask = edge_mask.at[idx, idx].set(True)\n",
    "    return edge_mask\n",
    "\n",
    "\n",
    "def loss_fn_(score_model, key: PRNGKey, batch_size:int= 1024):\n",
    "\n",
    "    rng_time, rng_loss, rng_data, rng_condition, rng_edge_mask1, rng_edge_mask2 = jax.random.split(key, 6)\n",
    "    \n",
    "    # Generate data and random times\n",
    "    times = jax.random.uniform(rng_time, (batch_size, 1, 1), minval=T_min, maxval=1.0)\n",
    "    batch_xs = generate_data(rng_data, batch_size) # n, T_max, 1\n",
    "\n",
    "    # Node ids (can be subsampled but here we use all nodes)\n",
    "    ids = node_ids\n",
    "    \n",
    "\n",
    "    # Condition mask -> randomly condition on some data.\n",
    "    condition_mask = jax.random.bernoulli(rng_condition, 0.333, shape=(batch_xs.shape[0], batch_xs.shape[1]))\n",
    "    condition_mask_all_one = jnp.all(condition_mask, axis=-1, keepdims=True)\n",
    "    condition_mask *= condition_mask_all_one # Avoid conditioning on all nodes -> nothing to train...\n",
    "    condition_mask = condition_mask[..., None]\n",
    "    # Alternatively you can also set the condition mask manually to specific conditional distributions.\n",
    "    # condition_mask = jnp.zeros((3,), dtype=jnp.bool_)  # Joint mask\n",
    "    # condition_mask = jnp.array([False, True, True], dtype=jnp.bool_)  # Posterior mask\n",
    "    # condition_mask = jnp.array([True, False, False], dtype=jnp.bool_)  # Likelihod mask\n",
    "    \n",
    "    # You can also structure the base mask!\n",
    "    edge_mask = jnp.ones((4*batch_size//5, batch_xs.shape[1],batch_xs.shape[1]), dtype=jnp.bool_) # Dense default mask \n",
    "    \n",
    "    # Optional: Include marginal consistency\n",
    "    marginal_mask = jax.vmap(marginalize, in_axes=(0,None))(jax.random.split(rng_edge_mask1, (batch_size//5,)), edge_mask[0])\n",
    "    edge_masks = jnp.concatenate([edge_mask, marginal_mask], axis=0)\n",
    "    edge_masks = jax.random.choice(rng_edge_mask2, edge_masks, shape=(batch_size,), axis=0) # Randomly choose between dense and marginal mask\n",
    "    \n",
    "\n",
    "    # Forward diffusion, do not perturb conditioned data\n",
    "    # Will use the condition mask to mask to prevent adding noise for nodes that are conditioned.\n",
    "    # loss = denoising_score_matching_loss(params, rng_sample, times, batch_xs, condition_mask, model_fn= model_fn, mean_fn=sde.marginal_mean, std_fn = sde.marginal_stddev, weight_fn=weight_fn,node_ids=ids, condition_mask=condition_mask, edge_mask=edge_masks)\n",
    "    \n",
    "    loss = denoising_score_matching_loss(score_model, rng_loss, times, batch_xs, condition_mask, mean_fn=sde.marginal_mean, std_fn = sde.marginal_stddev, weight_fn=weight_fn,node_ids=ids, condition_mask=condition_mask, edge_mask=edge_masks)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5) Training\n",
    "\n",
    "Simple training loop (compatible with multiple GPUs, TPUs). Here simpy optimizing with Adam for a fixed amount of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "@nnx.jit\n",
    "def train_step(score_model, optimizer, rngs):\n",
    "    loss_fn = lambda score_model: loss_fn_(score_model, rngs.dist(), batch_size=batch_size)\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(score_model)\n",
    "    optimizer.update(grads)  # In place updates.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(137.058, dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step(score_model, optimizer, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d92af944e314024b0cf862af66c828a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56e7b0fd5a84bd896902f51f08e9865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     l \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:1081\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:338\u001b[0m, in \u001b[0;36mjit.<locals>.jit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;129m@graph\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 338\u001b[0m   pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mextract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwarg_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_jit_split_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_aliasing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctxtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m   pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m jitted_fn(\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39mpure_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpure_kwargs\n\u001b[1;32m    347\u001b[0m   )\n\u001b[1;32m    348\u001b[0m   _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[1;32m    349\u001b[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    350\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/extract.py:336\u001b[0m, in \u001b[0;36mto_tree\u001b[0;34m(tree, prefix, split_fn, map_non_graph_nodes, ctxtag, check_aliasing)\u001b[0m\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m check_aliasing:\n\u001b[1;32m    333\u001b[0m     check_consistent_aliasing(\n\u001b[1;32m    334\u001b[0m       leaf, leaf_prefix, node_prefixes\u001b[38;5;241m=\u001b[39mnode_prefixes\n\u001b[1;32m    335\u001b[0m     )\n\u001b[0;32m--> 336\u001b[0m   tree_node \u001b[38;5;241m=\u001b[39m \u001b[43msplit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m   leaves_out\u001b[38;5;241m.\u001b[39mappend(tree_node)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:96\u001b[0m, in \u001b[0;36m_jit_split_fn\u001b[0;34m(ctx, path, prefix, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prefix, StateSharding):\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m extract\u001b[38;5;241m.\u001b[39mNodeStates\u001b[38;5;241m.\u001b[39mfrom_split(\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;241m*\u001b[39mctx\u001b[38;5;241m.\u001b[39msplit(x, \u001b[38;5;241m*\u001b[39mprefix\u001b[38;5;241m.\u001b[39mfilters), metadata\u001b[38;5;241m=\u001b[39mprefix\n\u001b[1;32m     95\u001b[0m   )\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extract\u001b[38;5;241m.\u001b[39mNodeStates\u001b[38;5;241m.\u001b[39mfrom_split(\u001b[38;5;241m*\u001b[39m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:809\u001b[0m, in \u001b[0;36mSplitContext.split\u001b[0;34m(self, node, *filters)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\n\u001b[1;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m, node: A, \u001b[38;5;241m*\u001b[39mfilters: filterlib\u001b[38;5;241m.\u001b[39mFilter\n\u001b[1;32m    805\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[GraphDef[A], tpe\u001b[38;5;241m.\u001b[39mUnpack[\u001b[38;5;28mtuple\u001b[39m[GraphState, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    806\u001b[0m   ctx \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    807\u001b[0m     current_update_context(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctxtag) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctxtag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    808\u001b[0m   )\n\u001b[0;32m--> 809\u001b[0m   graphdef, state \u001b[38;5;241m=\u001b[39m \u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m   states \u001b[38;5;241m=\u001b[39m _split_state(state, filters)\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:404\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(node, ref_index)\u001b[0m\n\u001b[1;32m    402\u001b[0m   ref_index \u001b[38;5;241m=\u001b[39m RefMap()\n\u001b[1;32m    403\u001b[0m flat_state: \u001b[38;5;28mdict\u001b[39m[PathParts, StateLeaf] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 404\u001b[0m graphdef \u001b[38;5;241m=\u001b[39m \u001b[43m_graph_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graphdef, GraphState\u001b[38;5;241m.\u001b[39mfrom_flat_path(flat_state)\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:436\u001b[0m, in \u001b[0;36m_graph_flatten\u001b[0;34m(path, ref_index, flat_state, node)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[1;32m    435\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_node(value):\n\u001b[0;32m--> 436\u001b[0m     nodedef \u001b[38;5;241m=\u001b[39m \u001b[43m_graph_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     subgraphs\u001b[38;5;241m.\u001b[39mappend((key, nodedef))\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Variable):\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:436\u001b[0m, in \u001b[0;36m_graph_flatten\u001b[0;34m(path, ref_index, flat_state, node)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[1;32m    435\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_node(value):\n\u001b[0;32m--> 436\u001b[0m     nodedef \u001b[38;5;241m=\u001b[39m \u001b[43m_graph_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     subgraphs\u001b[38;5;241m.\u001b[39mappend((key, nodedef))\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Variable):\n",
      "    \u001b[0;31m[... skipping similar frames: _graph_flatten at line 436 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:436\u001b[0m, in \u001b[0;36m_graph_flatten\u001b[0;34m(path, ref_index, flat_state, node)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[1;32m    435\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_node(value):\n\u001b[0;32m--> 436\u001b[0m     nodedef \u001b[38;5;241m=\u001b[39m \u001b[43m_graph_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     subgraphs\u001b[38;5;241m.\u001b[39mappend((key, nodedef))\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Variable):\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:459\u001b[0m, in \u001b[0;36m_graph_flatten\u001b[0;34m(path, ref_index, flat_state, node)\u001b[0m\n\u001b[1;32m    451\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    452\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrays leaves are not supported, at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_str\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    453\u001b[0m       )\n\u001b[1;32m    454\u001b[0m     static_fields\u001b[38;5;241m.\u001b[39mappend((key, value))\n\u001b[1;32m    456\u001b[0m nodedef \u001b[38;5;241m=\u001b[39m NodeDef\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    457\u001b[0m   \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mnode_impl\u001b[38;5;241m.\u001b[39mtype,\n\u001b[1;32m    458\u001b[0m   index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m--> 459\u001b[0m   attributes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    460\u001b[0m   subgraphs\u001b[38;5;241m=\u001b[39msubgraphs,\n\u001b[1;32m    461\u001b[0m   static_fields\u001b[38;5;241m=\u001b[39mstatic_fields,\n\u001b[1;32m    462\u001b[0m   leaves\u001b[38;5;241m=\u001b[39mleaves,\n\u001b[1;32m    463\u001b[0m   metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    464\u001b[0m   index_mapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodedef\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.12/site-packages/flax/nnx/graph.py:459\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    451\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    452\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrays leaves are not supported, at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_str\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    453\u001b[0m       )\n\u001b[1;32m    454\u001b[0m     static_fields\u001b[38;5;241m.\u001b[39mappend((key, value))\n\u001b[1;32m    456\u001b[0m nodedef \u001b[38;5;241m=\u001b[39m NodeDef\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    457\u001b[0m   \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mnode_impl\u001b[38;5;241m.\u001b[39mtype,\n\u001b[1;32m    458\u001b[0m   index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m--> 459\u001b[0m   attributes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(key \u001b[38;5;28;01mfor\u001b[39;00m key, _ \u001b[38;5;129;01min\u001b[39;00m values),\n\u001b[1;32m    460\u001b[0m   subgraphs\u001b[38;5;241m=\u001b[39msubgraphs,\n\u001b[1;32m    461\u001b[0m   static_fields\u001b[38;5;241m=\u001b[39mstatic_fields,\n\u001b[1;32m    462\u001b[0m   leaves\u001b[38;5;241m=\u001b[39mleaves,\n\u001b[1;32m    463\u001b[0m   metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    464\u001b[0m   index_mapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodedef\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nepochs = 10\n",
    "rngs = nnx.Rngs(0)\n",
    "\n",
    "score_model.train()\n",
    "\n",
    "for _ in range(nepochs):\n",
    "    pbar = tqdm(range(5000))\n",
    "    l = 0\n",
    "    for j in pbar:\n",
    "        loss = train_step(score_model, optimizer, rngs)\n",
    "        l += loss.item()\n",
    "        if j % 10 == 0:\n",
    "            pbar.set_postfix(loss=l/(j+1))\n",
    "    # print(l)\n",
    "\n",
    "score_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6) Sampling from the joint and the marginals\n",
    "\n",
    "For this we will implement a simple SDE-based sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from probjax.utils.sdeint import sdeint\n",
    "\n",
    "condition_mask = jnp.zeros((nodes_max,))\n",
    "condition_value = jnp.zeros((nodes_max,))\n",
    "\n",
    "# Reverse SDE drift\n",
    "def drift_backward(t, x, node_ids=node_ids, condition_mask=condition_mask, edge_mask=None, score_fn = model_fn, replace_conditioned=True):\n",
    "    score = score_fn(params, t.reshape(-1, 1, 1), x.reshape(-1, len(node_ids), 1), node_ids,condition_mask[:len(node_ids)], edge_mask=edge_mask)\n",
    "    score = score.reshape(x.shape)\n",
    "\n",
    "    f =  sde.drift(t,x) - sde.diffusion(t,x)**2 * score\n",
    "    if replace_conditioned:\n",
    "        f = f * (1-condition_mask[:len(node_ids)])\n",
    "    \n",
    "    return f\n",
    "\n",
    "# Reverse SDE diffusion\n",
    "def diffusion_backward(t,x, node_ids=node_ids,condition_mask=condition_mask, replace_conditioned=True):\n",
    "    b =  sde.diffusion(t,x) \n",
    "    if replace_conditioned:\n",
    "        b = b * (1-condition_mask[:len(node_ids)])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "end_std = jnp.squeeze(sde.marginal_stddev(jnp.ones(1)))\n",
    "end_mean = jnp.squeeze(sde.marginal_mean(jnp.ones(1)))\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1,3,7,8))\n",
    "def sample_fn(key, shape, node_ids=node_ids, time_steps=500, condition_mask=jnp.zeros((nodes_max,), dtype=int), condition_value=jnp.zeros((nodes_max,)), edge_mask=None, score_fn = model_fn, replace_conditioned=True):\n",
    "    condition_mask = condition_mask[:len(node_ids)]\n",
    "    key1, key2 = jrandom.split(key, 2)\n",
    "    # Sample from noise distribution at time 1\n",
    "    x_T = jax.random.normal(key1, shape + (len(node_ids),)) * end_std[node_ids] + end_mean[node_ids]\n",
    "    \n",
    "    if replace_conditioned:\n",
    "        x_T = x_T * (1-condition_mask) + condition_value * condition_mask\n",
    "    # Sove backward sde\n",
    "    keys = jrandom.split(key2, shape)\n",
    "    ys = jax.vmap(lambda *args: sdeint(*args, noise_type=\"diagonal\"), in_axes= (0, None, None, 0, None), out_axes=0)(keys, lambda t, x: drift_backward(t, x, node_ids, condition_mask, edge_mask=edge_mask, score_fn=score_fn, replace_conditioned=replace_conditioned), lambda t, x: diffusion_backward(t, x, node_ids, condition_mask, replace_conditioned=replace_conditioned), x_T, jnp.linspace(1.,T_min, time_steps))\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full joint estimation\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (10000,), node_ids, condition_mask=jnp.zeros((nodes_max,), dtype=int), condition_value=jnp.zeros((nodes_max,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with use_style(\"pyloric\"):\n",
    "    fig,axes = pairplot(np.array(samples[:,-1,:]), figsize=(5,5), labels=[\"$\\\\theta_1$\", \"$x_1$\", \"$x_2$\"], diag_kind=\"kde\", color=\"black\", linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal estimation alone (if you leave out marginal consitstency in the loss, this will fail but the above will still work!)\n",
    "marginal_samples1  = sample_fn(jrandom.PRNGKey(0), (10000,), jnp.array([0,]), condition_mask=jnp.zeros((1,), dtype=int), condition_value=jnp.zeros((1,)))\n",
    "marginal_samples2  = sample_fn(jrandom.PRNGKey(0), (10000,), jnp.array([1,]), condition_mask=jnp.zeros((1,), dtype=int), condition_value=jnp.zeros((1,)))\n",
    "marginal_samples3 = sample_fn(jrandom.PRNGKey(0), (10000,), jnp.array([2,]), condition_mask=jnp.zeros((1,), dtype=int), condition_value=jnp.zeros((1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with use_style(\"pyloric\"):\n",
    "    fig, ax = plt.subplots(1,3, figsize=(5,2))\n",
    "    sns.histplot(marginal_samples1[:, -1, 0], bins=50, ax=ax[0], stat=\"density\")\n",
    "    sns.histplot(marginal_samples2[:, -1, 0], bins=50, ax=ax[1], stat=\"density\")\n",
    "    sns.histplot(marginal_samples3[:, -1, 0], bins=50, ax=ax[2], stat=\"density\")\n",
    "    sns.kdeplot(data[:, 0, 0], ax=ax[0], color=\"black\", linewidth=2)\n",
    "    sns.kdeplot(data[:, 1, 0], ax=ax[1], color=\"black\", linewidth=2)\n",
    "    sns.kdeplot(data[:, 2, 0], ax=ax[2], color=\"black\", linewidth=2)\n",
    "    \n",
    "    ax[0].set_xlim(-10,10)\n",
    "    ax[1].set_xlim(-5,5)\n",
    "    ax[2].set_xlim(-5,5)\n",
    "    fig.suptitle(\"Correct individual marginal estimation\")\n",
    "    for ax in ax:\n",
    "        ax.yaxis.set_visible(False)\n",
    "        # remove y spines\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Arbitrary conditional distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_posterior(theta, x1=None, x2=None):\n",
    "    potential_theta = partial(log_potential, x1=x1, x2=x2)\n",
    "    potential_post = potential_theta(theta)\n",
    "    potential_post = potential_post - potential_post.max()\n",
    "    potential_post = jnp.exp(potential_post)\n",
    "    potential_post = potential_post / jnp.trapz(potential_post, x=theta)\n",
    "    return potential_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full conditional estimation\n",
    "theta = jnp.linspace(-10, 10, 1000)\n",
    "x_o = data[4,:,0]\n",
    "true_post = true_posterior(theta, x_o[1], x_o[2])\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (10000,), node_ids, condition_mask=jnp.array([0,1,1], dtype=jnp.bool_), condition_value=x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_theta = samples[...,-1, 0]\n",
    "with use_style(\"pyloric\"):\n",
    "    fig = plt.figure(figsize=(5, 2))\n",
    "    sns.histplot(samples_theta, bins=50, stat=\"density\")\n",
    "    plt.plot(theta, true_post, color=\"black\", label=\"True posterior\")\n",
    "    exact_patch = mpatches.Patch(color='black', label='Exact')\n",
    "    approx_patch = mpatches.Patch(color='C0', label='Approx.')\n",
    "    plt.legend(handles=[exact_patch, approx_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial conditional estimation\n",
    "theta = jnp.linspace(-10, 10, 1000)\n",
    "x_o = data[4,:,0]\n",
    "true_post = true_posterior(theta, x_o[1], None)\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (10000,), node_ids, condition_mask=jnp.array([0,1,0], dtype=int), condition_value=x_o, time_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "samples_theta = samples[...,-1, 0]\n",
    "with use_style(\"pyloric\"):\n",
    "    fig = plt.figure(figsize=(5, 2))\n",
    "    sns.histplot(samples_theta, bins=80, stat=\"density\")\n",
    "    plt.plot(theta, true_post, color=\"black\", label=\"True posterior\")\n",
    "    exact_patch = mpatches.Patch(color='black', label='Exact')\n",
    "    approx_patch = mpatches.Patch(color='C0', label='Approx.')\n",
    "    plt.legend(handles=[exact_patch, approx_patch])\n",
    "    plt.xlim(-10, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Arbitrary constraints\n",
    "\n",
    "Here a simplified version constraint conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified sampling with guidance...\n",
    "\n",
    "def s(t):\n",
    "    # Some scaling function\n",
    "    t = jnp.atleast_1d(t)\n",
    "    return jnp.exp(-t**2*5)*100\n",
    "\n",
    "def log_step_fun(t,x,a,b):\n",
    "    # Step_fn constraint -> Intervals\n",
    "    scale = s(t)\n",
    "    x1 = jax.nn.log_sigmoid(jnp.sum(scale * (x - a), axis=-1))\n",
    "    x2 = jax.nn.log_sigmoid(jnp.sum(-scale * (x - b), axis=-1))\n",
    "\n",
    "    return x1 + x2\n",
    "\n",
    "def log_linear_fn_approximation(t,x, a):\n",
    "    # Linear constrait <s,a> = 0.\n",
    "    scale = s(t)\n",
    "    a = a.reshape(-1,x.shape[1],1)\n",
    "    x1 = jax.nn.log_sigmoid(scale *jnp.sum((x * a), axis=1))\n",
    "    x2 = jax.nn.log_sigmoid(-scale *jnp.sum((x * a), axis=1))\n",
    "    return x1 + x2\n",
    "\n",
    "def log_polytope_fn_approximation(t,x, A):\n",
    "    # Polytope constraint \n",
    "    scale = s(t)\n",
    "    a = x.reshape(-1, x.shape[1])\n",
    "    constraint = jax.nn.relu(scale * (jnp.matmul(a, A.T) - 1.)).max(axis=-1)\n",
    "    constraint = jax.nn.log_sigmoid(-constraint) \n",
    "    return constraint\n",
    "\n",
    "\n",
    "\n",
    "step_fn_score = jax.grad(lambda *args: log_step_fun(*args).sum(), argnums=1)\n",
    "linear_fn_score = jax.grad(lambda *args: log_linear_fn_approximation(*args).sum(), argnums=1)\n",
    "polytope_fn_score = jax.grad(lambda *args: log_polytope_fn_approximation(*args).sum(), argnums=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wappers around score functions to include the constraints\n",
    "\n",
    "def interval_score(params, t, x, node_ids, condition_mask, edge_mask, a,b):\n",
    "    condition_mask = condition_mask[:len(node_ids)].reshape(-1,len(node_ids), 1)\n",
    "    score = model_fn(params,t, x, node_ids=node_ids, condition_mask=jnp.zeros_like(condition_mask), edge_mask=edge_mask)\n",
    "    tweedies_x0_estimator = (x + sde.marginal_stddev(t, jnp.array([1.]))**2 * score)/sde.marginal_mean(t, jnp.array([1.])) # Predict x0\n",
    "    interval_score_est = step_fn_score(t,tweedies_x0_estimator,a,b).reshape(-1, len(node_ids), 1) * condition_mask.reshape(-1, len(node_ids), 1)\n",
    "    return score + interval_score_est\n",
    "\n",
    "def linear_score(params, t, x, node_ids, condition_mask, edge_mask, a):\n",
    "    condition_mask = condition_mask[:len(node_ids)].reshape(-1,len(node_ids), 1)\n",
    "    score = model_fn(params,t, x, node_ids=node_ids, condition_mask=jnp.zeros_like(condition_mask), edge_mask=edge_mask)\n",
    "    tweedies_x0_estimator = (x + sde.marginal_stddev(t, jnp.array([1.]))**2 * score)/sde.marginal_mean(t, jnp.array([1.])) # Predict x0\n",
    "    linear_score_est = linear_fn_score(t,tweedies_x0_estimator,a) * condition_mask.reshape(-1, len(node_ids), 1)\n",
    "    return score + linear_score_est\n",
    "\n",
    "def polytope_score(params, t, x,  node_ids, condition_mask, edge_mask, A):\n",
    "    condition_mask = condition_mask[:len(node_ids)].reshape(-1,len(node_ids), 1)\n",
    "    score = model_fn(params,t, x, node_ids=node_ids, condition_mask=jnp.zeros_like(condition_mask), edge_mask=edge_mask)\n",
    "    tweedies_x0_estimator = (x + sde.marginal_stddev(t, jnp.array([1.]))**2 * score)/sde.marginal_mean(t, jnp.array([1.])) # Predict x0\n",
    "    polytope_score_est = polytope_fn_score(t,tweedies_x0_estimator,A) #* condition_mask.reshape(-1, len(node_ids), 1)\n",
    "    return score + polytope_score_est\n",
    "\n",
    "score_fn1 = partial(interval_score, a=2.*jnp.ones(1), b=jnp.ones(1)*3)\n",
    "score_fn3 = partial(linear_score, a=jnp.array([1., 5.]))\n",
    "score_fn4 = partial(polytope_score, A=0.3*jax.random.normal(jrandom.PRNGKey(0), (8,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples1 = sample_fn(jrandom.PRNGKey(0), (1000,), time_steps=1000, node_ids=jnp.array([0,1]), condition_mask=jnp.array([0,1], dtype=int), score_fn=score_fn1, replace_conditioned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples2 = sample_fn(jrandom.PRNGKey(0), (1000,), time_steps=1000, node_ids=jnp.array([0,1]), condition_mask=jnp.array([1,1], dtype=int), score_fn=score_fn3, replace_conditioned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples3 = sample_fn(jrandom.PRNGKey(0), (1000,), time_steps=1000, node_ids=jnp.array([0,1]), condition_mask=jnp.array([1,1], dtype=int), score_fn=score_fn4, replace_conditioned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliarly for plotting\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    def pot(x):\n",
    "        return jnp.exp(log_polytope_fn_approximation(0.001, x, 0.3*jax.random.normal(jrandom.PRNGKey(0), (8,2))))\n",
    "\n",
    "\n",
    "    potential_fn = jax.vmap(jax.scipy.stats.gaussian_kde(data[:,[0,1], 0].T, bw_method=\"silverman\"))\n",
    "    x = jnp.linspace(data[:, 0, 0].min(), data[:, 0, 0].max(), 200)\n",
    "    y = jnp.linspace(data[:, 1, 0].min(), data[:, 1, 0].max(), 200)\n",
    "    X, Y = jnp.meshgrid(x, y)\n",
    "    pos = jnp.dstack((X, Y))\n",
    "    Z_true = potential_fn(pos.reshape(-1,2)).reshape(200,200)\n",
    "    Z = pot(pos.reshape(-1,2)).reshape(200,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scoresbibm.plot import use_style\n",
    "with use_style(\"pyloric\"):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(4., 4.5), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "    # 2D scatter plot\n",
    "    l = axs[1].contour(X, Y, Z,colors=\"tab:red\", levels=[0.4], alpha=0.5, linewidths=3)\n",
    "    axs[1].contourf(X, Y, Z_true, cmap=\"Greys\", levels=200, vmin=0, alpha=0.9)\n",
    "    axs[1].scatter(samples1[:, -1, 0], samples1[:, -1, 1], s=1, alpha=0.2, color=\"tab:green\")\n",
    "    axs[1].scatter(samples2[:, -1, 0], samples2[:, -1, 1], s=1, alpha=0.05, color=\"tab:blue\")\n",
    "    axs[1].scatter(samples3[:, -1, 0], samples3[:, -1, 1], s=1, alpha=0.2, color=\"tab:red\")\n",
    "    axs[1].set_xlim(-10, 10)\n",
    "    axs[1].set_ylim(-5, 5)\n",
    "    axs[1].set_xlabel(r\"$\\theta$\")\n",
    "    axs[1].set_ylabel(r\"$x_1$\")\n",
    "\n",
    "    # 1D marginal plot\n",
    "    _ = sns.histplot(samples1[:, -1, 0], ax=axs[0], bins=20, color=\"tab:green\", stat=\"density\")\n",
    "    _ = sns.histplot(samples2[:, -1, 0], ax=axs[0], bins=20,color=\"tab:blue\", stat=\"density\")\n",
    "    _ = sns.histplot(samples3[:, -1, 0], ax=axs[0],bins=20, color=\"tab:red\", stat=\"density\")\n",
    "    axs[0].set_xlim(-10, 10)\n",
    "    axs[0].set_xticklabels([])\n",
    "    axs[0].set_yticklabels([])\n",
    "    axs[0].set_ylabel(\"\")\n",
    "    axs[0].yaxis.set_visible(False)\n",
    "    axs[1].set_xticks([-10,0,10])\n",
    "    axs[1].set_yticks([-5,0,5])\n",
    "    \n",
    "    axs[0].legend([r\"$p(\\theta|x_1 \\in [2,3])$\", r\"$p(\\theta|x_1 + \\theta = 0)$\", r\"$p(\\theta|(x_1,\\theta)\\in S)$\"], ncol=3, loc=\"upper center\", bbox_to_anchor=(0.5, 1.5),columnspacing=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Change priors or likelihoods\n",
    "\n",
    "\n",
    "$$ p(\\theta) \\propto \\exp\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right) $$\n",
    "$$ \\nabla_\\theta \\log p(\\theta) = \\frac{\\theta - \\mu}{\\sigma^2} $$\n",
    "\n",
    "In training we have $\\sigma^2 = 9$.\n",
    "Now for any $\\alpha$ we have\n",
    "$$ p(\\theta)^\\alpha = \\exp\\left(-\\frac{\\alpha(\\theta - \\mu)^2}{2\\sigma^2}\\right) = \\exp\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2/\\alpha}\\right) $$\n",
    "\n",
    "So if we want a certain variance $\\sigma_0^2$. All we have to do is to multiply the score by $\\alpha = \\sigma^2/\\sigma_0^2$.\n",
    "\n",
    "If we want to change the mean then we have to add $\\mu_0 - \\mu / \\sigma^2$ to the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score function wrappers with manipulations\n",
    "def score_prior_change(params, t, x, node_ids, condition_mask, edge_mask, node_ids_to_change, scale=1., shift=0.):\n",
    "\n",
    "    index = jnp.searchsorted(node_ids,node_ids_to_change)    \n",
    "    score_unconditioned = model_fn(params, t, x[:,index], node_ids=node_ids_to_change, condition_mask=jnp.zeros_like(node_ids_to_change))\n",
    "\n",
    "    score_conditional = model_fn(params, t, x, node_ids=node_ids, condition_mask=condition_mask, edge_mask=edge_mask)\n",
    "    score_conditional = score_conditional.at[:,index].set(scale * (score_unconditioned - shift) + (score_conditional[:,index] - score_unconditioned))\n",
    "    \n",
    "    return score_conditional\n",
    "\n",
    "def score_likelihood_change(params, t, x, node_ids, condition_mask, edge_mask, node_ids_to_change, scale=1., shift=0.):\n",
    "\n",
    "    index = jnp.searchsorted(node_ids,node_ids_to_change)    \n",
    "    score_unconditioned = model_fn(params, t, x[:,index], node_ids=node_ids_to_change, condition_mask=jnp.zeros_like(node_ids_to_change))\n",
    "\n",
    "    score_conditional = model_fn(params, t, x, node_ids=node_ids, condition_mask=condition_mask, edge_mask=edge_mask)\n",
    "    score_conditional =  score_conditional.at[:,index].set(score_unconditioned + (scale*(score_conditional[:,index] - score_unconditioned)) - shift)\n",
    "    \n",
    "    return score_conditional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(-10, 10, 1000)\n",
    "potential_theta = partial(log_potential, x1=jnp.zeros((1,)), x2=None, mean_scale=jnp.sqrt(12.))\n",
    "potential_post = potential_theta(x)\n",
    "potential_post = potential_post - potential_post.max()\n",
    "potential_post = jnp.exp(potential_post)\n",
    "potential_post = potential_post / jnp.trapz(potential_post, x=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to N(0, 2) prior -> shift = 9/4\n",
    "score_fn_prior_change = partial(score_prior_change, scale=9/12., shift=0., node_ids_to_change=jnp.array([0]))\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (5000,), time_steps=500, node_ids=jnp.array([0,1]), condition_mask=jnp.array([0,1], dtype=int), condition_value=jnp.zeros((2,)),  edge_mask=None, score_fn =score_fn_prior_change)\n",
    "with use_style(\"pyloric\"):\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = plt.gca()\n",
    "    sns.histplot(samples[:, -1, 0], bins=100, stat=\"density\", label= \"Approx.\")\n",
    "    plt.plot(x, jax.scipy.stats.norm.pdf(x, 0, 2), color=\"black\", linestyle=\"--\", label=\"Prior\")\n",
    "    plt.plot(x, potential_post, color=\"black\", label=\"Exact\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel(r\"$\\theta$\")\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_xticks([-10,0,10])   \n",
    "    ax.set_xlim(-10,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(-10, 10, 1000)\n",
    "potential_theta = partial(log_potential, x1=jnp.zeros((1,)), x2=None, mean_scale=1, mean_loc=2)\n",
    "potential_post = potential_theta(x)\n",
    "potential_post = potential_post - potential_post.max()\n",
    "potential_post = jnp.exp(potential_post)\n",
    "potential_post = potential_post / jnp.trapz(potential_post, x=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to N(2, 1) prior -> shift = 9/2, loc = 2/9\n",
    "score_fn_prior_change = partial(score_prior_change, scale=9/2, shift=-2/9, node_ids_to_change=jnp.array([0]))\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (2000,), time_steps=500, node_ids=jnp.array([0,1]), condition_mask=jnp.array([0,1], dtype=int), condition_value=jnp.zeros((2,)),  edge_mask=None, score_fn =score_fn_prior_change)\n",
    "\n",
    "with use_style(\"pyloric\"):\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = plt.gca()\n",
    "    sns.histplot(samples[:, -1, 0], bins=50, stat=\"density\", label= \"Approx.\")\n",
    "    plt.plot(x, jax.scipy.stats.norm.pdf(x, 2., np.sqrt(2.)), color=\"black\", linestyle=\"--\", label=\"Prior\")\n",
    "    plt.plot(x, potential_post, color=\"black\", label=\"Exact\")\n",
    "    plt.legend()\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_xticks([-10,0,10])   \n",
    "    plt.xlabel(r\"$\\theta$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(-10, 10, 1000)\n",
    "potential_theta = partial(log_potential, x1=jnp.zeros((1,)), x2=None, sigma_x1=jnp.sqrt(0.05))\n",
    "potential_post = potential_theta(x)\n",
    "potential_post = potential_post - potential_post.max()\n",
    "potential_post = jnp.exp(potential_post)\n",
    "potential_post = potential_post / jnp.trapz(potential_post, x=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood very certain\n",
    "score_fn_likelihood_change = partial(score_likelihood_change, scale=0.5**2/0.05, shift=0., node_ids_to_change=jnp.array([0]))\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (2000,), time_steps=500, node_ids=jnp.array([0,1]), condition_mask=jnp.array([0,1], dtype=int), condition_value=jnp.zeros((2,)),  edge_mask=None, score_fn =score_fn_likelihood_change)\n",
    "\n",
    "with use_style(\"pyloric\"):\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = plt.gca()\n",
    "    sns.histplot(samples[:, -1, 0], bins=200, stat=\"density\")\n",
    "    plt.plot(x, potential_post, color=\"black\")\n",
    "    plt.legend([\"exact\", \"approx.\"], loc=\"upper left\")\n",
    "    plt.xlim(-10,10)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_xticks([-10,0,10])   \n",
    "    plt.xlabel(r\"$\\theta$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.linspace(-10, 10, 1000)\n",
    "potential_theta = partial(log_potential, x1=jnp.zeros((1,)), x2=None, sigma_x1=2.)\n",
    "potential_post = potential_theta(x)\n",
    "potential_post = potential_post - potential_post.max()\n",
    "potential_post = jnp.exp(potential_post)\n",
    "potential_post = potential_post / jnp.trapz(potential_post, x=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood very certain\n",
    "score_fn_likelihood_change = partial(score_likelihood_change, scale=0.5**2/4., shift=0., node_ids_to_change=jnp.array([0]))\n",
    "samples = sample_fn(jrandom.PRNGKey(0), (10000,), time_steps=500, node_ids=jnp.array([0,1]), condition_mask=jnp.array([0,1], dtype=int), condition_value=jnp.zeros((2,)),  edge_mask=None, score_fn =score_fn_likelihood_change)\n",
    "\n",
    "with use_style(\"pyloric\"):\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = plt.gca()\n",
    "    sns.histplot(samples[:, -1, 0], bins=100, stat=\"density\")\n",
    "    plt.plot(x, potential_post, color=\"black\")\n",
    "    plt.legend([\"exact\", \"approx.\"], loc=\"upper left\")\n",
    "    plt.xlim(-10,10)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.set_xticks([-10,0,10])   \n",
    "    plt.xlabel(r\"$\\theta$\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
